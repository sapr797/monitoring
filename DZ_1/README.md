# Домашнее задание к занятию 13 «Введение в мониторинг»

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчётов, которые сохраняются на диск. 
Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

    1. Уровень доступности и работы HTTP-сервиса
        1.Задержки, время ответа эндпоинтов (через сколько секунд он получит отчет)
        2.Трафик, оличество запросов в секунду к конкретным эндпоинтам (видеть нагрузку на систему в динамике и коррелировать её с ростом потребления CPU/памяти)
        3.Ошибки, процент и абсолютное количество HTTP-ошибок (4xx, 5xx) (узнать, что сервис отвечает ошибками)
    2. Уровень ресурсов
        1.Процессор, загрузка CPU в процентах (user/system), Load Average (средняя длина очереди процессов).(«Расчеты загружают ЦПУ». Нужно отслеживать, не упирается ли система в потолок, чтобы вовремя расширить ресурсы или оптимизировать код расчетов)
        2.Память, использование RAM (used, cached), отсутствие места в swap (если расчеты потребляют много данных в оперативной памяти, нехватка RAM приведет к свопированию (замедлению) или (падению процесса))
        3.Дисковая подсистема, iowait (время ожидания диска), Utilization (загрузка диска, %), Queue length (длина очереди запросов) (При активной записи текстовых отчётов диск может стать "узким горлышком". Высокий iowait будет тормозить всю платформу, даже если CPU свободен)Свободное место
        3.Свободное место, процент занятого места на диске, скорость прироста данных (Отчёты лежат на диске. Если диск переполнится, новые отчёты не смогут записаться, сервис упадет с ошибкой)
    3. Бизнес-уровень
        1.Количество активных расчетов (Tasks in Progress) (Количество задач, выполняющихся в данный момент,  совпадает ли текущая нагрузка с ожидаемой)
        2.Очередь расчетов (Queue Size) Если расчеты асинхронны и встают в очередь, нужно знать её длину (Если очередь растет бесконечно, а CPU простаивает, значит, есть проблема с планировщиком задач или "утечка" запросов)
        3.Скорость генерации отчетов, в минуту/час (Бизнес-метрика эффективности работы платформы)
        4.Размер отчетов,  распределение размеров создаваемых файлов (прогнозировать заполнение диска, внезапный рост размера отчетов может указывать на ошибку в логике (запись логов в отчет вместо данных))
    4. Уровень зависимостей
        1.Кэш (Redis/БД),расчеты берут данные из БД (Подключение к БД, время ответа БД)

2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?
        Для менеджера продукта важно видеть картину глазами клиента: довольны ли пользователи, получают ли они отчёты вовремя и без проблем. Технические детали (RAM, inodes, load average) — это лишь инструменты, которые помогают нам поддерживать высокое качество сервиса
        Если внедрить простые и понятные бизнес-метрик, которые будут отражать реальный опыт клиентов:
      1. Доступность сервиса (Availability)
       Процент времени, когда платформа была доступна и могла принимать запросы на расчёты (Количество успешных HTTP-запросов, с кодом 200 делим на общее количество запросов).Вместо RAM (оперативная память) — Если он переполнен, системе становится тесно, она начинает тормозить или «выкидывать» задачи.
      2. Время получения отчёта (Response Time / Speed) (Как быстро клиент получает готовый отчёт после отправки запроса)
       Измеряем время от момента запроса до момента полной загрузки отчёта (среднее значение и 95-й перцентиль)
       Вместо inodes  — «паспорта» для файлов на диске. 
      3. Доля успешных расчётов (Success Rate) Процент запросов, которые завершились успешной выдачей отчёта, без ошибок.
      (Количество успешно сгенерированных отчётов делим на общее количество запросов на расчёт. Ошибки могут быть разными: нехватка места на диске, сбой вычислений, таймаут.)
      4. Количество обработанных запросов / отчётов (Throughput) (Насколько активно используется платформа и справляется ли она с растущим потоком клиентов) (Рост или падение этого показателя может сигнализировать об изменении спроса или о проблемах) вместо CPU la (Load Average) — сколько задач одновременно ждут своей очереди на выполнение процессором. (Если очередь слишком длинная, значит, процессор перегружен и всё работает медленно).
      5. Метрики, связанные с диском (Вместо «inodes» и «свободного места» можно показывать простой индикатор: «Готовность к сохранению новых отчётов». Если места на диске остаётся мало, система может предупреждать: «Возможны задержки при сохранении результатов»). 

3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

   Решение с использованием Open Source инструментов. Оно позволит разработчикам централизованно просматривать ошибки приложений, не заходя на каждый сервер вручную.
   Предлагаемое решение: стек Grafana Loki + Promtail (или Fluent Bit)
    Promtail (агент): Устанавливается на каждом сервере с приложением. Собирает логи из файлов (/var/log/application/*.log) и отправляет их в Loki. Он умеет добавлять метки (labels) — имя сервера, приложения.
    Loki (хранилище и обработчик): Центральный сервер, который принимает логи от Promtail, индексирует только метаданные (метки), а сами логи хранит в сжатом виде, экономит дисковое пространство
    Grafana (интерфейс): В веб-интерфейсе Grafana добавляется источник данных Loki, и разработчики получают удобный инструмент для поиска и фильтрации логов по любым меткам, а также по тексту ошибок. Можно строить дашборды с графиками количества ошибок во времени.
    Все компоненты имеют лицензию Open Source.
    Loki и Promtail распространяются в виде одного бинарного файла или Docker-образа
    Loki не требует мощного кластера. Его можно развернуть на виртуальной машине, где работает Prometheus или другой сервис.
    Интерфейс Grafana позволяет быстро перейти к просмотру логов. Возможность делать запросы на языке LogQL

    1. Выделить сервер (использовать существующий) для установки Loki и Grafana.
    2. Установить Loki (Docker или бинарный файл) и настроить хранение логов на диске (локальное или объектное).
    3. Установить Grafana и подключить к ней Loki как источник данных.
    4. На каждом сервере с приложением установить Promtail, настроить его на чтение файлов логов и указать адрес Loki.
    5. Настроить метки (labels) в Promtail, чтобы разработчики могли фильтровать логи по окружению (dev/stage/prod), по 
       имени микросервиса, по хосту и т.д.
    6. Создать в Grafana несколько готовых запросов для быстрого просмотра ошибок и настроить алерты на появление новых
       ошибок (через Grafana Alerting).

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA = 99% по http-кодам ответов. 
Этот параметр вычисляется по формуле: summ_2xx_requests/summ_all_requests. Он не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

  summ_2xx_requests / summ_all_requests даёт низкое значение, потому что она учитывает только успешные ответы с кодом 2xx. Однако в системе могут присутствовать ответы с другими кодами, не являющиеся ошибками:
  3xx (редиректы) —  не попадают в числитель. Если доля редиректов составляет около 30%, то показатель будет держаться на уровне 70%.
  1xx (информационные) —  могут быть, но реже.
  Возможны ситуации, когда в summ_all_requests учитываются запросы, которые вообще не получили HTTP-ответа (обрывы соединения, таймауты) и не классифицируются по кодам и такие события могут снижать долю успешных ответов.


## Дополнительное задание* (со звёздочкой) 

Выполнение этого задания необязательно и никак не влияет на получение зачёта по домашней работе.

_____

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. 

Вы, как опытный системный администратор, знаете, что системная информация сервера лежит в директории `/proc`. Также знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав всё, вы спроектировали приложение, которое:

- является python3-скриптом;
- собирает метрики из папки `/proc`;
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY — год, MM — месяц, DD — день);
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp — временная метка, int, unixtimestamp;
  + metric_1 — метрика 1;
  + metric_2 — метрика 2;
  
     ...
     
  + metric_N — метрика N.
  
- сбор метрик происходит каждую минуту по cron-расписанию.

Для успешного выполнения задания нужно привести:

* работающий код python3-скрипта;
* конфигурацию cron-расписания;
* пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не меньше пяти записей.

Дополнительная информация:

1. Количество собираемых метрик должно быть не меньше четырёх.
1. По желанию можно не ограничивать себя только сбором метрик из `/proc`.

---

### Как оформить решение задания

Выполненное домашнее задание пришлите в виде ссылки на .md-файл в вашем репозитории.


---
