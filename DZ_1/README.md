# Домашнее задание к занятию "13.Системы мониторинга"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?
#
 
 1. Уровень доступности и работы HTTP-сервиса
        1.Задержки, время ответа эндпоинтов (через сколько секунд он получит отчет)
        2.Трафик, оличество запросов в секунду к конкретным эндпоинтам (видеть нагрузку на систему в динамике и коррелировать её с ростом потребления CPU/памяти)
        3.Ошибки, процент и абсолютное количество HTTP-ошибок (4xx, 5xx) (узнать, что сервис отвечает ошибками)
    2. Уровень ресурсов
        1.Процессор, загрузка CPU в процентах (user/system), Load Average (средняя длина очереди процессов).(«Расчеты загружают ЦПУ». Нужно отслеживать, не упирается ли система в потолок, чтобы вовремя расширить ресурсы или оптимизировать код расчетов)
        2.Память, использование RAM (used, cached), отсутствие места в swap (если расчеты потребляют много данных в оперативной памяти, нехватка RAM приведет к свопированию (замедлению) или (падению процесса))
        3.Дисковая подсистема, iowait (время ожидания диска), Utilization (загрузка диска, %), Queue length (длина очереди запросов) (При активной записи текстовых отчётов диск может стать "узким горлышком". Высокий iowait будет тормозить всю платформу, даже если CPU свободен)Свободное место
        3.Свободное место, процент занятого места на диске, скорость прироста данных (Отчёты лежат на диске. Если диск переполнится, новые отчёты не смогут записаться, сервис упадет с ошибкой)
    3. Бизнес-уровень
        1.Количество активных расчетов (Tasks in Progress) (Количество задач, выполняющихся в данный момент,  совпадает ли текущая нагрузка с ожидаемой)
        2.Очередь расчетов (Queue Size) Если расчеты асинхронны и встают в очередь, нужно знать её длину (Если очередь растет бесконечно, а CPU простаивает, значит, есть проблема с планировщиком задач или "утечка" запросов)
        3.Скорость генерации отчетов, в минуту/час (Бизнес-метрика эффективности работы платформы)
        4.Размер отчетов,  распределение размеров создаваемых файлов (прогнозировать заполнение диска, внезапный рост размера отчетов может указывать на ошибку в логике (запись логов в отчет вместо данных))
    4. Уровень зависимостей
        1.Кэш (Redis/БД),расчеты берут данные из БД (Подключение к БД, время ответа БД)


2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?
#

Для менеджера продукта важно видеть картину глазами клиента: довольны ли пользователи, получают ли они отчёты вовремя и без проблем. Технические детали (RAM, inodes, load average) — это лишь инструменты, которые помогают нам поддерживать высокое качество сервиса
        Если внедрить простые и понятные бизнес-метрик, которые будут отражать реальный опыт клиентов:
      1. Доступность сервиса (Availability)
       Процент времени, когда платформа была доступна и могла принимать запросы на расчёты (Количество успешных HTTP-запросов, с кодом 200 делим на общее количество запросов).Вместо RAM (оперативная память) — Если он переполнен, системе становится тесно, она начинает тормозить или «выкидывать» задачи.
      2. Время получения отчёта (Response Time / Speed) (Как быстро клиент получает готовый отчёт после отправки запроса)
       Измеряем время от момента запроса до момента полной загрузки отчёта (среднее значение и 95-й перцентиль)
       Вместо inodes  — «паспорта» для файлов на диске. 
      3. Доля успешных расчётов (Success Rate) Процент запросов, которые завершились успешной выдачей отчёта, без ошибок.
      (Количество успешно сгенерированных отчётов делим на общее количество запросов на расчёт. Ошибки могут быть разными: нехватка места на диске, сбой вычислений, таймаут.)
      4. Количество обработанных запросов / отчётов (Throughput) (Насколько активно используется платформа и справляется ли она с растущим потоком клиентов) (Рост или падение этого показателя может сигнализировать об изменении спроса или о проблемах) вместо CPU la (Load Average) — сколько задач одновременно ждут своей очереди на выполнение процессором. (Если очередь слишком длинная, значит, процессор перегружен и всё работает медленно).
      5. Метрики, связанные с диском (Вместо «inodes» и «свободного места» можно показывать простой индикатор: «Готовность к сохранению новых отчётов». Если места на диске остаётся мало, система может предупреждать: «Возможны задержки при сохранении результатов»). 

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?
#

Решение с использованием Open Source инструментов. Оно позволит разработчикам централизованно просматривать ошибки приложений, не заходя на каждый сервер вручную.
   Предлагаемое решение: стек Grafana Loki + Promtail (или Fluent Bit)
    Promtail (агент): Устанавливается на каждом сервере с приложением. Собирает логи из файлов (/var/log/application/*.log) и отправляет их в Loki. Он умеет добавлять метки (labels) — имя сервера, приложения.
    Loki (хранилище и обработчик): Центральный сервер, который принимает логи от Promtail, индексирует только метаданные (метки), а сами логи хранит в сжатом виде, экономит дисковое пространство
    Grafana (интерфейс): В веб-интерфейсе Grafana добавляется источник данных Loki, и разработчики получают удобный инструмент для поиска и фильтрации логов по любым меткам, а также по тексту ошибок. Можно строить дашборды с графиками количества ошибок во времени.
    Все компоненты имеют лицензию Open Source.
    Loki и Promtail распространяются в виде одного бинарного файла или Docker-образа
    Loki не требует мощного кластера. Его можно развернуть на виртуальной машине, где работает Prometheus или другой сервис.
    Интерфейс Grafana позволяет быстро перейти к просмотру логов. Возможность делать запросы на языке LogQL

    1. Выделить сервер (использовать существующий) для установки Loki и Grafana.
    2. Установить Loki (Docker или бинарный файл) и настроить хранение логов на диске (локальное или объектное).
    3. Установить Grafana и подключить к ней Loki как источник данных.
    4. На каждом сервере с приложением установить Promtail, настроить его на чтение файлов логов и указать адрес Loki.
    5. Настроить метки (labels) в Promtail, чтобы разработчики могли фильтровать логи по окружению (dev/stage/prod), по 
       имени микросервиса, по хосту и т.д.
    6. Создать в Grafana несколько готовых запросов для быстрого просмотра ошибок и настроить алерты на появление новых
       ошибок (через Grafana Alerting).

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?
#

 summ_2xx_requests / summ_all_requests даёт низкое значение, потому что она учитывает только успешные ответы с кодом 2xx. Однако в системе могут присутствовать ответы с другими кодами, не являющиеся ошибками:
  3xx (редиректы) —  не попадают в числитель. Если доля редиректов составляет около 30%, то показатель будет держаться на уровне 70%.
  1xx (информационные) —  могут быть, но реже.
  Возможны ситуации, когда в summ_all_requests учитываются запросы, которые вообще не получили HTTP-ответа (обрывы соединения, таймауты) и не классифицируются по кодам и такие события могут снижать долю успешных ответов.


5. Опишите основные плюсы и минусы pull и push систем мониторинга.
#
Системы мониторинга используют две основные модели сбора данных: Pull (тянуть) и Push (толкать). Выбор зависит от конкретной архитектуры и требований к инфраструктуре. Понимание этих различий критически важно для построения эффективного и надёжного мониторинга..
  Модель Pull (Тянуть)
  В этой модели центральный сервер мониторинга (Prometheus) инициирует соединение и периодически запрашивает («скрейпит») метрики с целевых сервисов по известному эндпоинту (обычно /metrics) .
  Плюсы Pull-модели
    1. Централизованный контроль и упрощённое управление конфигурацией: система мониторинга определяет, с какой периодичностью и какие именно метрики собирать. Это позволяет унифицировать политики сбора данных для всех сервисов. Вся 
       конфигурация хранится централизованно, что упрощает её изменение и аудит .
    2. Простота определения «живости» сервиса (Health Checking): Если сервис не ответил на запрос метрик - он недоступен или работает некорректно. Это даёт встроенный и надёжный механизм проверки состояния целевых узлов, так как метрика 
       успешности скрейпа (Prometheus) служит индикатором здоровья .
    3. Более высокая безопасность: При Pull-модели целевые сервисы не открывают исходящих соединений. Им не нужно знать адрес и иметь учётные данные для доступа к центральному серверу. Достаточно открыть входящий порт только для доверенных 
       мониторинговых систем, что упрощает настройку сетевых экранов и ACL .
    4. Лёгкость отладки и обнаружения сервисов (Service Discovery): Для проверки корректности работы достаточно перейти по URL эндпоинта в браузере. Pull-модель прекрасно интегрируется с системами обнаружения сервисов (Consul, Kubernetes), 
       автоматически начиная сбор метрик с новых экземпляров приложений .
  Минусы Pull-модели
    1. Сложность масштабирования и «единая точка отказа»: Центральный сервер может стать узким местом или точкой отказа, при росте числа целевых сервисов. В распределённой инфраструктуре может потребоваться запуск нескольких экземпляров 
       Pull-агентов и сложная координация между ними (шардирование), что усложняет архитектуру .
    2. Проблемы с сетевой доступностью: Мониторинговый сервер должен иметь прямой сетевой доступ к каждому целевому сервису. В микросервисной архитектуре, разнесённой по разным ЦОДам, сетям или окружениям (изолированные подсети VPC), 
       обеспечение такой связности может быть нетривиальной задачей .
    3. Непригодность для короткоживущих задач: Пакетные задания, Cron-скрипты или serverless-функции, которые работают считанные секунды или минуты, могут завершиться раньше, чем мониторинговый сервер успеет опросить их. Метрики таких задач 
       будут безвозвратно потеряны .

Модель Push (Толкать)
Здесь инициатива исходит от самих сервисов или агентов на них: они самостоятельно отправляют метрики на центральный приёмник (Graphite, InfluxDB) .
Плюсы Push-модели
    1. Простота сетевой конфигурации: Сервисам нужен исходящий доступ до центрального сборщика метрик. Им не нужно открывать входящие порты, что проще согласовывать с командами безопасности и настраивать в облачных средах .
    2. Естественная поддержка короткоживущих процессов: Пакетное задание может само отправить свои метрики в момент завершения работы, они не будут потеряны. Это идеальный вариант для мониторинга CI/CD пайплайнов, батчей и Serverless-функций .
    3. Более высокая горизонтальная масштабируемость: Добавление новых сервисов не увеличивает нагрузку на центральный сборщик пропорционально их количеству, так как сервисы сами распределяют нагрузку по отправке. Это позволяет легко 
       масштабировать систему сбора данных .
    4. Возможность отправки детальных данных: Сервис может отправлять метрики с произвольной, высокой частотой ( несколько раз в секунду), что позволяет видеть пиковые нагрузки, незаметные при редком опросе .

Минусы Push-модели
    1. Сложность диагностики «живости» сервиса: Если сервис перестал присылать метрики, сложно понять причину: он упал, завис, или просто проблемы с сетью. Центральная система не может отличить отсутствие данных от неработающего сервиса без 
       дополнительной логики и данных из систем обнаружения .
    2. Риск потери данных и перегрузки: Если центральный приёмник или сеть временно недоступны, отправляемые данные могут быть безвозвратно потеряны, если на стороне отправителя не реализованы сложные механизмы буферизации и повторных отправок.
       Также сервисы могут перегрузить приёмник, начав отправлять слишком много данных .
    3. Более жёсткая связанность (Coupling) с системой мониторинга: Сервис должен знать адрес, порт, протокол и, способ аутентификации для отправки метрик. Это создаёт зависимость кода приложения от конкретной инфраструктуры мониторинга .
    4. Сложность управления конфигурациями: При отсутствии централизованного конфигурационного сервера изменение адреса приёмника метрик потребует переконфигурирования и перезапуска всех агентов и сервисов по отдельности .
  
6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

    - Prometheus 
    - TICK
    - Zabbix
    - VictoriaMetrics
    - Nagios
#
Prometheus - Pull, Сервер сам периодически опрашивает (scrape) целевые сервисы 
                 по HTTP 
    TICK - Push, Данные активно отправляются от агентов к центральной системе хранения, а 
               не вытягиваются ею. Агент сбора (Telegraf): "толкатель", собирает метрики с сервера или приложений и отправляет (пушит) их в базу данных InfluxDB или другие системы .База данных (InfluxDB): "приемник", оптимизирована для приема данных по протоколу Push, ожидая, когда клиенты (Telegraf) пришлют ей метрики 

    Zabbix -  Push /Гибрид. По умолчанию использует Push: агент активно отправляет данные 
              на сервер поддерживает режим "активных проверок" и может работать в Pull, что делает его гибридным
    VictoriaMetrics -  Гибрид (Push + Pull).Поддерживает обе модели в равной степени. 
                      Может как принимать данные по протоколам Push (InfluxDB, Graphite, OpenTSDB), так и самостоятельно "вытягивать" их, выступая в роли заменителя Prometheus 
    Nagios - Push, Работает по модели, где агенты (плагины), установленные на хостах, выполняют проверки и отправляют результаты на центральный сервер

7. Склонируйте себе [репозиторий](https://github.com/influxdata/sandbox/tree/master) и запустите TICK-стэк, 
используя технологии docker и docker-compose.

В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (`http://localhost:8888`). 

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим `Z`, например
`./data:/var/lib:Z`
#

Рисунок 7_001.png

8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        
    - Нажмите на кнопку Add a query
    - Изучите вывод интерфейса и выберите БД telegraf.autogen
    - В `measurments` выберите cpu->host->telegraf-getting-started, а в `fields` выберите usage_system. Внизу появится график утилизации cpu.
    - Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.
#
Рисунок 8_02.png - 8_05.png

9. Изучите список [telegraf inputs](https://github.com/influxdata/telegraf/tree/master/plugins/inputs). 
Добавьте в конфигурацию telegraf следующий плагин - [docker](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/docker):
```
[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
```

Дополнительно вам может потребоваться донастройка контейнера telegraf в `docker-compose.yml` дополнительного volume и 
режима privileged:
```
  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"
```

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список `measurments` в 
веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.

Рисунок 9_01.png - 9_08.png


## Дополнительное задание (со звездочкой*) - необязательно к выполнению

1. Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.

Рисунок Доп_000.png - Доп_002.png

2. В веб-интерфейсе откройте вкладку `Dashboards`. Попробуйте создать свой dashboard с отображением:

    - утилизации ЦПУ
    - количества использованного RAM
    - утилизации пространства на дисках
    - количество поднятых контейнеров
    - аптайм
    - ...
    - фантазируйте)
    
    ---
Рисунок Доп_003.png - Доп_004.png

### Как оформить ДЗ?


Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

